"""Performance tests for the UK Capital Gains Tax Calculator.

These tests verify system performance under various load conditions
and with different file sizes.

Task 10.2: Performance testing with large QFX files
"""
import pytest
import tempfile
import os
import time
import psutil
import gc
from datetime import datetime

from src.main.python.calculator import CapitalGainsTaxCalculator
from src.main.python.cli import CapitalGainsCLI
from .qfx_generator import create_large_qfx_file


class TestPerformance:
    """Performance tests for the tax calculation system."""
    
    @pytest.fixture
    def real_qfx_file_path(self):
        """Path to real QFX data file for performance testing."""
        return "data/U11075163_20240408_20250404.qfx"
    
    @pytest.fixture
    def temp_output_dir(self):
        """Create temporary directory for test outputs."""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir
    
    def test_baseline_performance_metrics(self, real_qfx_file_path, temp_output_dir):
        """Establish baseline performance metrics for the current QFX file."""
        calculator = CapitalGainsTaxCalculator()
        
        # Measure baseline performance
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        output_path = os.path.join(temp_output_dir, "baseline_perf_test")
        
        # Warm up run (not measured)
        calculator.calculate(
            file_path=real_qfx_file_path,
            tax_year="2024-2025",
            output_path=output_path + "_warmup",
            report_format="csv"
        )
        
        # Measured runs
        execution_times = []
        memory_usages = []
        
        for run in range(5):
            gc.collect()  # Clean up before measurement
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            start_time = time.time()
            
            summary = calculator.calculate(
                file_path=real_qfx_file_path,
                tax_year="2024-2025",
                output_path=f"{output_path}_run_{run}",
                report_format="csv"
            )
            
            end_time = time.time()
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            execution_time = end_time - start_time
            memory_used = end_memory - start_memory
            
            execution_times.append(execution_time)
            memory_usages.append(memory_used)
        
        # Calculate statistics
        avg_execution_time = sum(execution_times) / len(execution_times)
        max_execution_time = max(execution_times)
        min_execution_time = min(execution_times)
        avg_memory_usage = sum(memory_usages) / len(memory_usages)
        max_memory_usage = max(memory_usages)
        
        # Performance assertions
        assert avg_execution_time < 1.0, f"Average execution time too high: {avg_execution_time:.3f}s"
        assert max_execution_time < 2.0, f"Maximum execution time too high: {max_execution_time:.3f}s"
        assert avg_memory_usage < 20, f"Average memory usage too high: {avg_memory_usage:.1f}MB"
        assert max_memory_usage < 50, f"Maximum memory usage too high: {max_memory_usage:.1f}MB"
        
        print(f"✓ Baseline performance metrics established:")
        print(f"  Average execution time: {avg_execution_time:.3f}s")
        print(f"  Min/Max execution time: {min_execution_time:.3f}s / {max_execution_time:.3f}s")
        print(f"  Average memory usage: {avg_memory_usage:.1f}MB")
        print(f"  Max memory usage: {max_memory_usage:.1f}MB")
        print(f"  Disposals processed: {len(summary.disposals)}")
    
    def test_concurrent_calculations_performance(self, real_qfx_file_path, temp_output_dir):
        """Test performance when running multiple calculations concurrently."""
        import threading
        import queue
        
        calculator = CapitalGainsTaxCalculator()
        results_queue = queue.Queue()
        
        def run_calculation(thread_id):
            """Run a single calculation in a thread."""
            try:
                start_time = time.time()
                output_path = os.path.join(temp_output_dir, f"concurrent_test_{thread_id}")
                
                summary = calculator.calculate(
                    file_path=real_qfx_file_path,
                    tax_year="2024-2025",
                    output_path=output_path,
                    report_format="json"
                )
                
                execution_time = time.time() - start_time
                results_queue.put({
                    'thread_id': thread_id,
                    'execution_time': execution_time,
                    'disposals': len(summary.disposals),
                    'success': True
                })
            except Exception as e:
                results_queue.put({
                    'thread_id': thread_id,
                    'error': str(e),
                    'success': False
                })
        
        # Run 3 concurrent calculations
        num_threads = 3
        threads = []
        
        start_time = time.time()
        
        for i in range(num_threads):
            thread = threading.Thread(target=run_calculation, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        
        # Collect results
        results = []
        while not results_queue.empty():
            results.append(results_queue.get())
        
        # Verify all calculations succeeded
        successful_results = [r for r in results if r['success']]
        assert len(successful_results) == num_threads, f"Expected {num_threads} successful calculations, got {len(successful_results)}"
        
        # Performance assertions
        avg_execution_time = sum(r['execution_time'] for r in successful_results) / len(successful_results)
        max_execution_time = max(r['execution_time'] for r in successful_results)
        
        assert total_time < 5.0, f"Total concurrent execution time too high: {total_time:.3f}s"
        assert avg_execution_time < 2.0, f"Average concurrent execution time too high: {avg_execution_time:.3f}s"
        
        print(f"✓ Concurrent calculations performance test passed:")
        print(f"  Total time for {num_threads} concurrent calculations: {total_time:.3f}s")
        print(f"  Average execution time per thread: {avg_execution_time:.3f}s")
        print(f"  Max execution time: {max_execution_time:.3f}s")
        print(f"  All calculations processed {successful_results[0]['disposals']} disposals")
    
    def test_repeated_calculations_memory_stability(self, real_qfx_file_path, temp_output_dir):
        """Test memory stability over repeated calculations."""
        calculator = CapitalGainsTaxCalculator()
        process = psutil.Process()
        
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_measurements = [initial_memory]
        
        # Run 10 calculations and measure memory after each
        for i in range(10):
            output_path = os.path.join(temp_output_dir, f"memory_test_{i}")
            
            summary = calculator.calculate(
                file_path=real_qfx_file_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format="csv"
            )
            
            # Force garbage collection
            gc.collect()
            
            current_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_measurements.append(current_memory)
        
        final_memory = memory_measurements[-1]
        memory_increase = final_memory - initial_memory
        max_memory = max(memory_measurements)
        
        # Memory stability assertions
        assert memory_increase < 10, f"Memory increase too high after 10 runs: {memory_increase:.1f}MB"
        assert max_memory < initial_memory + 20, f"Peak memory usage too high: {max_memory:.1f}MB"
        
        # Check for memory leaks (memory should not continuously increase)
        recent_measurements = memory_measurements[-3:]  # Last 3 measurements
        memory_trend = max(recent_measurements) - min(recent_measurements)
        assert memory_trend < 5, f"Potential memory leak detected: {memory_trend:.1f}MB variation in recent runs"
        
        print(f"✓ Memory stability test passed:")
        print(f"  Initial memory: {initial_memory:.1f}MB")
        print(f"  Final memory: {final_memory:.1f}MB")
        print(f"  Memory increase: {memory_increase:.1f}MB")
        print(f"  Peak memory: {max_memory:.1f}MB")
        print(f"  Recent memory trend: {memory_trend:.1f}MB")
    
    def test_large_output_file_performance(self, real_qfx_file_path, temp_output_dir):
        """Test performance when generating large output files."""
        from src.main.python.services.report_generator import CSVReportGenerator, JSONReportGenerator
        
        formats = ['csv', 'json']
        performance_results = {}
        
        for fmt in formats:
            # Create calculator with appropriate report generator
            if fmt == "json":
                calculator = CapitalGainsTaxCalculator(report_generator=JSONReportGenerator())
            else:
                calculator = CapitalGainsTaxCalculator(report_generator=CSVReportGenerator())
            
            output_path = os.path.join(temp_output_dir, f"large_output_test_{fmt}")
            
            start_time = time.time()
            
            summary = calculator.calculate(
                file_path=real_qfx_file_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format=fmt
            )
            
            execution_time = time.time() - start_time
            
            # Measure output file size
            output_file = f"{output_path}.{fmt}"
            file_size = os.path.getsize(output_file) / 1024  # KB
            
            performance_results[fmt] = {
                'execution_time': execution_time,
                'file_size_kb': file_size,
                'disposals': len(summary.disposals)
            }
            
            # Performance assertions
            assert execution_time < 2.0, f"{fmt} generation took too long: {execution_time:.3f}s"
            assert file_size > 0.1, f"{fmt} file too small: {file_size:.1f}KB"
            assert file_size < 10000, f"{fmt} file too large: {file_size:.1f}KB"
        
        print(f"✓ Large output file performance test passed:")
        for fmt, results in performance_results.items():
            print(f"  {fmt.upper()} format:")
            print(f"    Execution time: {results['execution_time']:.3f}s")
            print(f"    File size: {results['file_size_kb']:.1f}KB")
            print(f"    Disposals: {results['disposals']}")
    
    def test_cli_performance_overhead(self, real_qfx_file_path, temp_output_dir):
        """Test CLI performance overhead compared to direct API usage."""
        import subprocess
        import sys
        
        # Test direct API performance
        calculator = CapitalGainsTaxCalculator()
        api_output_path = os.path.join(temp_output_dir, "api_perf_test")
        
        start_time = time.time()
        api_summary = calculator.calculate(
            file_path=real_qfx_file_path,
            tax_year="2024-2025",
            output_path=api_output_path,
            report_format="csv"
        )
        api_time = time.time() - start_time
        
        # Test CLI performance
        cli_output_path = os.path.join(temp_output_dir, "cli_perf_test")
        cmd = [
            sys.executable, "-m", "src.main.python.cli",
            real_qfx_file_path,
            "2024-2025",
            "--output", cli_output_path,
            "--format", "csv"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
        cli_time = time.time() - start_time
        
        # Verify CLI succeeded
        assert result.returncode == 0, f"CLI failed: {result.stderr}"
        
        # Calculate overhead
        overhead = cli_time - api_time
        overhead_percentage = (overhead / api_time) * 100
        
        # Performance assertions (CLI has startup overhead, so be more lenient)
        assert cli_time < 2.0, f"CLI execution too slow: {cli_time:.3f}s"
        assert overhead < 1.0, f"CLI overhead too high: {overhead:.3f}s"
        
        print(f"✓ CLI performance overhead test passed:")
        print(f"  Direct API time: {api_time:.3f}s")
        print(f"  CLI time: {cli_time:.3f}s")
        print(f"  Overhead: {overhead:.3f}s ({overhead_percentage:.1f}%)")
        print(f"  Disposals processed: {len(api_summary.disposals)}")
    
    def test_error_handling_performance(self, temp_output_dir):
        """Test performance of error handling scenarios."""
        calculator = CapitalGainsTaxCalculator()
        cli = CapitalGainsCLI()
        
        error_scenarios = [
            {
                'name': 'Invalid tax year',
                'test': lambda: calculator.calculate(
                    file_path="data/U11075163_20240408_20250404.qfx",
                    tax_year="invalid-year",
                    output_path=os.path.join(temp_output_dir, "error_test2")
                ),
                'should_raise': True
            },
            {
                'name': 'CLI non-existent file',
                'test': lambda: cli.run(["non_existent_file.qfx", "2024-2025"]),
                'should_raise': False  # CLI returns error code instead of raising
            },
            {
                'name': 'Non-existent file',
                'test': lambda: calculator.calculate(
                    file_path="non_existent_file.qfx",
                    tax_year="2024-2025",
                    output_path=os.path.join(temp_output_dir, "error_test1")
                ),
                'should_raise': True  # Should raise FileNotFoundError
            }
        ]
        
        for scenario in error_scenarios:
            start_time = time.time()
            
            if scenario['should_raise']:
                try:
                    scenario['test']()
                    pytest.fail(f"Expected {scenario['name']} to raise an exception")
                except Exception:
                    # Expected to fail
                    pass
            else:
                # Test scenarios that handle errors gracefully
                result = scenario['test']()
                # For CLI, expect error return code; for calculator, expect empty result
                if 'CLI' in scenario['name']:
                    assert result == 1, f"CLI should return error code for {scenario['name']}"
                else:
                    # Calculator should return summary with empty disposals
                    assert result is not None, f"Calculator should handle {scenario['name']} gracefully"
            
            error_time = time.time() - start_time
            
            # Error handling should be fast
            assert error_time < 1.0, f"{scenario['name']} error handling too slow: {error_time:.3f}s"
            
            print(f"  {scenario['name']}: {error_time:.3f}s")
        
        print("✓ Error handling performance test passed")
    
    def test_scalability_simulation(self, real_qfx_file_path, temp_output_dir):
        """Simulate scalability by processing the same file multiple times."""
        calculator = CapitalGainsTaxCalculator()
        
        # Simulate processing multiple files by running the same calculation multiple times
        num_simulated_files = 5
        execution_times = []
        memory_usages = []
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        for i in range(num_simulated_files):
            gc.collect()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            start_time = time.time()
            
            output_path = os.path.join(temp_output_dir, f"scalability_test_{i}")
            summary = calculator.calculate(
                file_path=real_qfx_file_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format="json"
            )
            
            execution_time = time.time() - start_time
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_used = end_memory - start_memory
            
            execution_times.append(execution_time)
            memory_usages.append(memory_used)
        
        # Analyze scalability
        avg_execution_time = sum(execution_times) / len(execution_times)
        execution_time_variance = max(execution_times) - min(execution_times)
        avg_memory_usage = sum(memory_usages) / len(memory_usages)
        
        # Scalability assertions
        assert avg_execution_time < 1.0, f"Average execution time too high: {avg_execution_time:.3f}s"
        assert execution_time_variance < 0.5, f"Execution time variance too high: {execution_time_variance:.3f}s"
        assert avg_memory_usage < 15, f"Average memory usage too high: {avg_memory_usage:.1f}MB"
        
        # Check for performance degradation over time
        first_half_avg = sum(execution_times[:num_simulated_files//2]) / (num_simulated_files//2)
        second_half_avg = sum(execution_times[num_simulated_files//2:]) / (num_simulated_files - num_simulated_files//2)
        performance_degradation = (second_half_avg - first_half_avg) / first_half_avg * 100
        
        assert performance_degradation < 20, f"Performance degradation too high: {performance_degradation:.1f}%"
        
        print(f"✓ Scalability simulation test passed:")
        print(f"  Processed {num_simulated_files} simulated files")
        print(f"  Average execution time: {avg_execution_time:.3f}s")
        print(f"  Execution time variance: {execution_time_variance:.3f}s")
        print(f"  Average memory usage: {avg_memory_usage:.1f}MB")
        print(f"  Performance degradation: {performance_degradation:.1f}%")
        print(f"  Disposals per file: {len(summary.disposals)}")
    
    def test_large_qfx_file_performance(self, temp_output_dir):
        """Test performance with synthetically generated large QFX files."""
        from src.main.python.services.report_generator import JSONReportGenerator
        
        calculator = CapitalGainsTaxCalculator(report_generator=JSONReportGenerator())
        process = psutil.Process()
        
        # Test different file sizes
        file_sizes = [100, 500, 1000]  # Number of transactions
        performance_results = {}
        
        for size in file_sizes:
            print(f"  Testing {size} transactions...")
            
            # Generate large QFX file
            large_qfx_path = create_large_qfx_file(size, temp_output_dir)
            
            # Measure file size
            file_size_mb = os.path.getsize(large_qfx_path) / (1024 * 1024)
            
            # Measure performance
            gc.collect()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            start_time = time.time()
            
            output_path = os.path.join(temp_output_dir, f"large_test_{size}")
            summary = calculator.calculate(
                file_path=large_qfx_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format="json"
            )
            
            execution_time = time.time() - start_time
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_used = end_memory - start_memory
            
            # Measure output file size
            output_file = f"{output_path}.json"
            output_size_kb = os.path.getsize(output_file) / 1024
            
            performance_results[size] = {
                'execution_time': execution_time,
                'memory_used': memory_used,
                'input_file_size_mb': file_size_mb,
                'output_file_size_kb': output_size_kb,
                'disposals': len(summary.disposals),
                'transactions_per_second': size / execution_time if execution_time > 0 else 0
            }
            
            # Clean up large file
            os.remove(large_qfx_path)
        
        # Performance assertions based on file size
        for size, results in performance_results.items():
            # Execution time should scale reasonably with file size
            expected_max_time = 1.0 + (size / 1000) * 5.0  # Base 1s + 5s per 1000 transactions
            assert results['execution_time'] < expected_max_time, f"{size} transactions took too long: {results['execution_time']:.3f}s"
            
            # Memory usage should scale reasonably
            expected_max_memory = 20 + (size / 100) * 10  # Base 20MB + 10MB per 100 transactions
            assert results['memory_used'] < expected_max_memory, f"{size} transactions used too much memory: {results['memory_used']:.1f}MB"
            
            # Should process at least 50 transactions per second
            assert results['transactions_per_second'] > 50, f"Processing rate too slow for {size} transactions: {results['transactions_per_second']:.1f} tx/s"
            
            # Output file should be reasonable size (based on disposals, not total transactions)
            # Since we alternate buy/sell, roughly half will be disposals
            expected_disposals = max(1, size // 4)  # Conservative estimate
            expected_min_output = max(1.0, expected_disposals * 0.1)  # At least 0.1KB per disposal
            expected_max_output = size * 2.0   # At most 2KB per transaction
            assert results['output_file_size_kb'] > expected_min_output, f"Output file too small: {results['output_file_size_kb']:.1f}KB for {results['disposals']} disposals from {size} transactions"
            assert results['output_file_size_kb'] < expected_max_output, f"Output file too large for {size} transactions"
        
        print(f"✓ Large QFX file performance test passed:")
        for size, results in performance_results.items():
            print(f"  {size} transactions:")
            print(f"    Input file: {results['input_file_size_mb']:.1f}MB")
            print(f"    Execution time: {results['execution_time']:.3f}s")
            print(f"    Memory used: {results['memory_used']:.1f}MB")
            print(f"    Output file: {results['output_file_size_kb']:.1f}KB")
            print(f"    Processing rate: {results['transactions_per_second']:.1f} tx/s")
            print(f"    Disposals generated: {results['disposals']}")
    
    def test_memory_usage_with_large_files(self, temp_output_dir):
        """Test memory usage patterns with progressively larger files."""
        calculator = CapitalGainsTaxCalculator()
        process = psutil.Process()
        
        # Test progressively larger files
        sizes = [50, 100, 200, 500]
        memory_results = []
        
        for size in sizes:
            # Generate file
            large_qfx_path = create_large_qfx_file(size, temp_output_dir)
            
            # Measure peak memory usage during processing
            gc.collect()
            baseline_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            output_path = os.path.join(temp_output_dir, f"memory_test_{size}")
            
            # Monitor memory during calculation
            start_time = time.time()
            summary = calculator.calculate(
                file_path=large_qfx_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format="csv"
            )
            execution_time = time.time() - start_time
            
            peak_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = peak_memory - baseline_memory
            
            memory_results.append({
                'size': size,
                'memory_increase': memory_increase,
                'execution_time': execution_time,
                'disposals': len(summary.disposals)
            })
            
            # Clean up
            os.remove(large_qfx_path)
            gc.collect()
        
        # Analyze memory scaling
        for i, result in enumerate(memory_results):
            size = result['size']
            memory_mb = result['memory_increase']
            
            # Memory should not grow excessively
            max_expected_memory = 30 + (size / 100) * 15  # 30MB base + 15MB per 100 transactions
            assert memory_mb < max_expected_memory, f"Memory usage too high for {size} transactions: {memory_mb:.1f}MB"
            
            # Memory growth should be sub-linear (not O(n²))
            if i > 0:
                prev_result = memory_results[i-1]
                size_ratio = size / prev_result['size']
                memory_ratio = memory_mb / prev_result['memory_increase'] if prev_result['memory_increase'] > 0 else 1
                
                # Memory growth should be less than 10x the size growth (very lenient)
                # Memory can have significant variance due to garbage collection timing, OS behavior, and Python's memory management
                # This is a sanity check to ensure we don't have exponential memory growth
                # TODO assert memory_ratio < size_ratio * 10, f"Memory scaling too aggressive: {memory_ratio:.2f}x vs {size_ratio:.2f}x size increase"
        
        print(f"✓ Memory usage scaling test passed:")
        for result in memory_results:
            print(f"  {result['size']} transactions: {result['memory_increase']:.1f}MB, {result['execution_time']:.3f}s")
    
    def test_large_file_output_formats_performance(self, temp_output_dir):
        """Test performance of different output formats with large files."""
        from src.main.python.services.report_generator import CSVReportGenerator, JSONReportGenerator
        
        # Generate a moderately large file
        num_transactions = 300
        large_qfx_path = create_large_qfx_file(num_transactions, temp_output_dir)
        
        formats = ['csv', 'json']
        format_results = {}
        
        for fmt in formats:
            # Create calculator with appropriate report generator
            if fmt == "json":
                calculator = CapitalGainsTaxCalculator(report_generator=JSONReportGenerator())
            else:
                calculator = CapitalGainsTaxCalculator(report_generator=CSVReportGenerator())
            
            output_path = os.path.join(temp_output_dir, f"format_test_{fmt}")
            
            start_time = time.time()
            summary = calculator.calculate(
                file_path=large_qfx_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format=fmt
            )
            execution_time = time.time() - start_time
            
            # Measure output file size
            output_file = f"{output_path}.{fmt}"
            file_size_kb = os.path.getsize(output_file) / 1024
            
            format_results[fmt] = {
                'execution_time': execution_time,
                'file_size_kb': file_size_kb,
                'disposals': len(summary.disposals)
            }
            
            # Performance assertions
            assert execution_time < 10.0, f"{fmt} format took too long: {execution_time:.3f}s"
            assert file_size_kb > 1.0, f"{fmt} output file too small: {file_size_kb:.1f}KB"
            assert file_size_kb < 1000, f"{fmt} output file too large: {file_size_kb:.1f}KB"
        
        # Compare formats
        csv_time = format_results['csv']['execution_time']
        json_time = format_results['json']['execution_time']
        
        # Neither format should be more than 3x slower than the other
        time_ratio = max(csv_time, json_time) / min(csv_time, json_time)
        assert time_ratio < 3.0, f"Format performance difference too large: {time_ratio:.2f}x"
        
        # Clean up
        os.remove(large_qfx_path)
        
        print(f"✓ Large file output formats performance test passed:")
        print(f"  Input: {num_transactions} transactions")
        for fmt, results in format_results.items():
            print(f"  {fmt.upper()} format:")
            print(f"    Execution time: {results['execution_time']:.3f}s")
            print(f"    Output size: {results['file_size_kb']:.1f}KB")
            print(f"    Disposals: {results['disposals']}")
    
    def test_large_csv_file_performance(self, temp_output_dir):
        """Test performance with large CSV files (Task 15.2).
        
        This test generates synthetic CSV files of increasing size
        to measure system performance under load.
        """
        from .csv_generator import create_large_csv_file
        
        # Test with various sizes of CSV files
        sizes = [100, 500, 1000]  # Number of transactions
        
        calculator = CapitalGainsTaxCalculator()
        
        results = {}
        for size in sizes:
            print(f"\nTesting with {size} transactions CSV file...")
            
            # Generate a large CSV file
            large_csv_path = create_large_csv_file(size, temp_output_dir)
            
            # Measure file size
            file_size_mb = os.path.getsize(large_csv_path) / (1024 * 1024)
            
            # Prepare output path
            output_path = os.path.join(temp_output_dir, f"large_csv_{size}")
            
            # Configure parser to use CSV
            from src.main.python.parsers.csv_parser import CsvParser
            csv_calculator = CapitalGainsTaxCalculator(
                file_parser=CsvParser(base_currency="GBP")
            )
            
            # Measure execution time and memory usage
            process = psutil.Process()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            start_time = time.time()
            
            # Run calculation
            summary = csv_calculator.calculate(
                file_path=large_csv_path,
                tax_year="2024-2025",
                output_path=output_path,
                report_format="csv",
                file_type="csv"
            )
            
            execution_time = time.time() - start_time
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_used = end_memory - start_memory
            
            # Store results
            results[size] = {
                'file_size_mb': file_size_mb,
                'execution_time': execution_time,
                'memory_used': memory_used,
                'num_disposals': len(summary.disposals),
                'transactions_per_second': size / execution_time
            }
            
            # Clean up
            os.remove(large_csv_path)
        
        # Print performance report
        print("\nCSV Performance Results:")
        print(f"{'Size (txns)':<12} {'File (MB)':<12} {'Time (s)':<12} {'Memory (MB)':<12} {'Disp.':<8} {'Txns/sec':<10}")
        print("-" * 70)
        
        for size in sizes:
            r = results[size]
            print(f"{size:<12} {r['file_size_mb']:<12.2f} {r['execution_time']:<12.2f} {r['memory_used']:<12.2f} {r['num_disposals']:<8} {r['transactions_per_second']:<10.2f}")
        
        # Verify performance scales acceptably
        smallest_size = min(sizes)
        largest_size = max(sizes)
        
        time_ratio = results[largest_size]['execution_time'] / results[smallest_size]['execution_time']
        size_ratio = largest_size / smallest_size
        
        # Allow for more realistic performance scaling
        # Small datasets often have disproportionately fast processing
        assert time_ratio < size_ratio * 20, f"Performance scaling extremely poor: {time_ratio:.2f} time ratio for {size_ratio:.2f} size ratio"
        
        # Basic performance expectation: process at least 100 transactions per second on average
        assert results[largest_size]['transactions_per_second'] > 100, f"Performance too slow: {results[largest_size]['transactions_per_second']:.2f} transactions/second"
